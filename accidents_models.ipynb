{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import h2o\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "from shapely.geometry import Polygon\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from h2o.automl import H2OAutoML\n",
    "from tpot import TPOTClassifier\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost\n",
    "from sklearn.metrics import mean_squared_error, r2_score, roc_auc_score\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_sub = pd.read_csv(\"C:\\\\Users\\\\reza3\\\\OneDrive\\\\Desktop\\\\AIT\\\\Machine learning\\\\group project\\\\data\\\\sub_accidents.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents_sub = accidents_sub[accidents_sub[\"Start_Year\"]>2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3047692, 37)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accidents_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = accidents_sub.drop(columns=['ID', 'Severity', 'Delay(min)', 'Street', 'City', 'County', 'State', 'Zipcode',\n",
    "       'Start_Year', 'Start_Month', 'Start_Day', 'Start_Lat', 'Start_Lng',\n",
    "       'Start_time','Distance(km)', 'Delay_ln', 'Severity_new'])\n",
    "Y = accidents_sub.loc[:, ['Severity', 'Severity_new', 'Delay(min)', 'Delay_ln', 'Distance(km)']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3047692, 20),\n",
       " (3047692, 5),\n",
       " (2742922, 20),\n",
       " (304770, 20),\n",
       " (2742922,),\n",
       " (304770,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y[\"Severity_new\"], test_size = 0.10, random_state=370, stratify=Y[\"Severity_new\"])\n",
    "\n",
    "assert len(X_train)  == len(Y_train)\n",
    "assert len(X_test)   == len(Y_test)\n",
    "X.shape, Y.shape,X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# fixing imbalance by under sampling (Tomek links) (it didn't help)\n",
    "tl = TomekLinks(n_jobs=-1, sampling_strategy=\"Majority\")\n",
    "\n",
    "# fit predictor and target variable\n",
    "X_train_tl, Y_train_tl = tl.fit_resample(X_train, Y_train[\"Severity_new\"])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3047692, 20), (3047692, 5), (490126, 20), (490126,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fixing imbalance by under sampling (random under sampling)\n",
    "rus = RandomUnderSampler(random_state=370, replacement=False)\n",
    "\n",
    "# fit predictor and target varialbe\n",
    "X_train_rus, Y_train_rus = rus.fit_resample(X_train, Y_train)\n",
    "\n",
    "X.shape, Y.shape, X_train_rus.shape, Y_train_rus.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried to fit a regression model with Delay and distance as labels but no appropriate model have found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model = SGDRegressor(max_iter=1000, tol=1e-3, random_state=370)\n",
    "\n",
    "model.fit(X_train, Y_train[\"Distance(km)\"])\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(Y_train[\"Distance(km)\"], y_train_pred)\n",
    "r2 = r2_score(Y_train[\"Distance(km)\"], y_train_pred)\n",
    "print(f'Mean Squared Error on Test Set: {mse}')\n",
    "print(f'R_squared on Test Set: {r2}')'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Severity_new\n",
       "0    2359090\n",
       "1     231448\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  LogisticRegression(n_jobs=-1, random_state=370) Scores:  [0.57 0.57 0.57 0.57 0.57] - Scores mean:  0.5707777215891273 - Scores std (lower better): 0.0016765492161903536\n",
      "[125476 152065   8439  18790]\n",
      "ROCAUC score: 0.5710860265028719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.45      0.61    277541\n",
      "           1       0.11      0.69      0.19     27229\n",
      "\n",
      "    accuracy                           0.47    304770\n",
      "   macro avg       0.52      0.57      0.40    304770\n",
      "weighted avg       0.86      0.47      0.57    304770\n",
      "\n",
      "Model:  RandomForestClassifier(n_jobs=-1, oob_score=True, random_state=370) Scores:  [0.62 0.62 0.62 0.62 0.63] - Scores mean:  0.6241578733076416 - Scores std (lower better): 0.0012007246685853084\n",
      "[171228 106313   9713  17516]\n",
      "ROCAUC score: 0.6301157092717378\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.62      0.75    277541\n",
      "           1       0.14      0.64      0.23     27229\n",
      "\n",
      "    accuracy                           0.62    304770\n",
      "   macro avg       0.54      0.63      0.49    304770\n",
      "weighted avg       0.87      0.62      0.70    304770\n",
      "\n",
      "Model:  XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=1, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=200, n_jobs=-1,\n",
      "              num_parallel_tree=None, random_state=None, ...) Scores:  [0.59 0.6  0.59 0.6  0.6 ] - Scores mean:  0.5961936357853479 - Scores std (lower better): 0.0023030092410731423\n",
      "[155007 122534   9854  17375]\n",
      "ROCAUC score: 0.5983038485616731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.56      0.70    277541\n",
      "           1       0.12      0.64      0.21     27229\n",
      "\n",
      "    accuracy                           0.57    304770\n",
      "   macro avg       0.53      0.60      0.45    304770\n",
      "weighted avg       0.87      0.57      0.66    304770\n",
      "\n",
      "Model:  AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1),\n",
      "                   learning_rate=0.001, n_estimators=200, random_state=370) Scores:  [0.54 0.53 0.54 0.54 0.54] - Scores mean:  0.5363784020304759 - Scores std (lower better): 0.001283698904513062\n",
      "[ 29996 247545    909  26320]\n",
      "ROCAUC score: 0.5373471002674453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.11      0.19    277541\n",
      "           1       0.10      0.97      0.17     27229\n",
      "\n",
      "    accuracy                           0.18    304770\n",
      "   macro avg       0.53      0.54      0.18    304770\n",
      "weighted avg       0.89      0.18      0.19    304770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=370, n_jobs=-1)\n",
    "rf = RandomForestClassifier(random_state=370, n_jobs=-1, oob_score=True)\n",
    "sgb = xgboost.XGBClassifier(max_depth=1, n_estimators=200, n_jobs=-1)\n",
    "ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200, learning_rate=0.001, random_state=370)\n",
    "\n",
    "models = [ lr, rf, sgb, ada]\n",
    "\n",
    "#perform cross validation using KFold\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "kfold = KFold(n_splits = 5, shuffle = True, random_state=370)\n",
    "\n",
    "for model in models:\n",
    "    score = cross_val_score(model, X_train_rus, Y_train_rus, cv=kfold, scoring='accuracy', n_jobs=-1)  #f1, recall, precision, accuracy\n",
    "    np.set_printoptions(precision = 2)\n",
    "    print(\"Model: \", model, \"Scores: \", score, \"- Scores mean: \", score.mean(), \"- Scores std (lower better):\", score.std()) \n",
    "    fit = model.fit(X_train_rus, Y_train_rus)\n",
    "    yhat = fit.predict(X_test)\n",
    "    print(confusion_matrix(Y_test, yhat).ravel())\n",
    "    print('ROCAUC score:',roc_auc_score(Y_test, yhat))      \n",
    "    print(classification_report(Y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 9, 'n_estimators': 200}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.57      0.71    277541\n",
      "           1       0.13      0.64      0.21     27229\n",
      "\n",
      "    accuracy                           0.58    304770\n",
      "   macro avg       0.53      0.61      0.46    304770\n",
      "weighted avg       0.87      0.58      0.66    304770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"n_estimators\": [100, 200, 300], \"criterion\": [\"gini\", \"entropy\"], \"max_depth\": np.arange(1, 10)}\n",
    "model = RandomForestClassifier(n_jobs=-1, random_state=370, oob_score=True)\n",
    "grid = GridSearchCV(model, param_grid, refit=True, n_jobs=-1)\n",
    "grid.fit(X_train_rus, Y_train_rus)\n",
    "print(grid.best_params_)\n",
    "yhat = grid.predict(X_test)\n",
    "print(classification_report(Y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative =  157810  False Negative =  9709 True Positive =  17520 False Positive =  9709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.57      0.71    277541\n",
      "           1       0.13      0.64      0.21     27229\n",
      "\n",
      "    accuracy                           0.58    304770\n",
      "   macro avg       0.53      0.61      0.46    304770\n",
      "weighted avg       0.87      0.58      0.66    304770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators= 200, criterion=\"gini\", max_depth= 9, n_jobs=-1, random_state=370)\n",
    "model.fit(X_train_rus, Y_train_rus)\n",
    "yhat = model.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, yhat).ravel()\n",
    "print(\"True Negative = \",tn, \" False Negative = \",fn, \"True Positive = \", tp, \"False Positive = \", fn)\n",
    "print(classification_report(Y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative =  159513  False Negative =  9900 True Positive =  17329 False Positive =  9900\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.57      0.71    277541\n",
      "           1       0.13      0.64      0.21     27229\n",
      "\n",
      "    accuracy                           0.58    304770\n",
      "   macro avg       0.53      0.61      0.46    304770\n",
      "weighted avg       0.87      0.58      0.67    304770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators= 200, criterion=\"gini\", max_depth= 9, n_jobs=-1, random_state=370, class_weight=\"balanced_subsample\")\n",
    "model.fit(X_train, Y_train)\n",
    "yhat = model.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, yhat).ravel()\n",
    "print(\"True Negative = \",tn, \" False Negative = \",fn, \"True Positive = \", tp, \"False Positive = \", fn)\n",
    "print(classification_report(Y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators= 200, criterion=\"gini\", max_depth= 9, n_jobs=-1, random_state=370, class_weight=\"balanced\")\n",
    "model.fit(X_train, Y_train)\n",
    "yhat = model.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test, yhat).ravel()\n",
    "print(\"True Negative = \",tn, \" False Negative = \",fn, \"True Positive = \", tp, \"False Positive = \", fn)\n",
    "print(classification_report(Y_test, yhat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
